# project_scraper.py (v7.0 - Blueprint Edition)
import os
import argparse
import fnmatch
from collections import defaultdict
import time

# ==============================================================================
# æ ¸å¿ƒé…ç½®æ–‡ä»¶ï¼šå®šä¹‰äº†æ¶æ„çš„â€œè“å›¾â€
# ==============================================================================

class ScraperConfig:
    """
    é…ç½®ç»è¿‡ç²¾ç®€ï¼Œåªå…³æ³¨å®šä¹‰é¡¹ç›®ç»“æ„ã€å…³ç³»å’Œå¥‘çº¦çš„æ ¸å¿ƒæ–‡ä»¶ã€‚
    """
    # è¾“å‡ºé¡ºåºä¼˜åŒ–ï¼Œä¼˜å…ˆå±•ç¤ºé«˜å±‚è®¾è®¡
    CATEGORY_ORDER = [
        "1_ARCHITECTURE_META",
        "2_ORCHESTRATION_AND_CONFIG",
        "3_DATABASE_SCHEMA",
        "4_AI_PROMPTS",
        "5_BACKEND_WIRING",
        "6_FRONTEND_WIRING",
    ]

    # ç²¾ç®€åçš„æ ¸å¿ƒæ–‡ä»¶æ¨¡å¼å®šä¹‰
    CORE_FILE_PATTERNS = {
        # 1. é¡¶å±‚è®¾è®¡æ–‡æ¡£
        "1_ARCHITECTURE_META": [
            'æ¡†æ¶.txt',
            'README.md', # åªæ•è·æ ¹ç›®å½•çš„README
        ],
        # 2. é¡¶å±‚ç¼–æ’ä¸æ ¸å¿ƒé…ç½®
        "2_ORCHESTRATION_AND_CONFIG": [
            'docker-compose.yml',
            'apps/frontend/Dockerfile',
            'apps/backend/apps/*/Dockerfile',
            'package.json',
            'pnpm-workspace.yaml',
            'tsconfig.json',
            'nest-cli.json',
            'turbo.json',
        ],
        # 3. æ•°æ®åº“éª¨æ¶
        "3_DATABASE_SCHEMA": [
            'apps/backend/prisma/schema.prisma',
        ],
        # 4. AI çš„â€œæºä»£ç â€ - æ ¸å¿ƒæ™ºèƒ½æ‰€åœ¨
        "4_AI_PROMPTS": [
            'libs/common/src/prompts/**/*.md',
        ],
        # 5. åç«¯â€œæ¥çº¿å›¾â€ (æ¨¡å—ã€æ§åˆ¶å™¨ã€ç½‘å…³)
        # [æ ¸å¿ƒç®€åŒ–] æ•…æ„æ’é™¤äº† '/**/*.service.ts'ï¼Œå› ä¸ºæˆ‘ä»¬æ›´å…³æ³¨æ¨¡å—å¦‚ä½•è¿æ¥ï¼Œè€Œéå…¶å†…éƒ¨å®ç°
        "5_BACKEND_WIRING": [
            'apps/backend/apps/*/src/main.ts',
            'apps/backend/apps/**/src/**/*.module.ts',
            'apps/backend/apps/**/src/**/*.controller.ts',
            'apps/backend/apps/**/src/**/*.gateway.ts',
        ],
        # 6. å‰ç«¯æ ¸å¿ƒç»“æ„
        "6_FRONTEND_WIRING": [
            'apps/frontend/src/main.js',
            'apps/frontend/src/router/index.js',
            'apps/frontend/src/stores/*.store.js',
            'apps/frontend/src/services/api.service.js'
        ],
    }

    # å¿½ç•¥åˆ—è¡¨ä¿æŒå¥å£®
    IGNORE_PATTERNS = [
        'node_modules/*', '.git/*', 'dist/*', 'build/*', 'coverage/*',
        '.vscode/*', '.idea/*', '__pycache__/*', 'dist-ssr/*', '.turbo/*',
        'playwright-report/*', 'test-results/*', 'nexus-data/*',
        '*.lock', '*.log', '.DS_Store', 'Thumbs.db',
        'monorepo_snapshot*.txt', 'project_snapshot*.txt',
        'æƒ³æ³•/*',
        '**/node_modules/**/*.md' # è¿›ä¸€æ­¥ç¡®ä¿ä¸æ•è·ä¾èµ–ä¸­çš„æ–‡æ¡£
    ]

# ==============================================================================
# çˆ¬è™«ä¸»é€»è¾‘ (ä¸ v6.0 ä¿æŒä¸€è‡´, æ— éœ€ä¿®æ”¹)
# ==============================================================================

class ProjectScraper:
    def __init__(self, project_path, output_file, config):
        self.project_path = os.path.abspath(project_path)
        self.output_file = output_file
        self.config = config
        self.files_by_category = defaultdict(list)
        self.total_files_scanned = 0

    def _log(self, message, indent=0):
        print(f"{'  ' * indent}{message}")

    def _is_ignored(self, path):
        path = path.replace(os.sep, '/')
        return any(fnmatch.fnmatch(path, pattern) for pattern in self.config.IGNORE_PATTERNS)

    def _classify_path(self, relative_path):
        path = relative_path.replace(os.sep, '/')
        for category, patterns in self.config.CORE_FILE_PATTERNS.items():
            if any(fnmatch.fnmatch(path, pattern) for pattern in patterns):
                return category
        return None

    def scrape(self):
        start_time = time.time()
        self._log(f"ğŸš€ [Blueprint Scraper] å¼€å§‹æ‰«æé¡¹ç›®æ¶æ„è“å›¾: {self.project_path}")

        for root, dirs, files in os.walk(self.project_path, topdown=True):
            # è¿‡æ»¤æ‰æ•´ä¸ªè¢«å¿½ç•¥çš„ç›®å½•æ ‘
            rel_root = os.path.relpath(root, self.project_path)
            if rel_root == '.': rel_root = ''
            
            dirs[:] = [d for d in dirs if not self._is_ignored(os.path.join(rel_root, d, ''))]
            
            for file in files:
                self.total_files_scanned += 1
                relative_path = os.path.join(rel_root, file)
                
                if self._is_ignored(relative_path):
                    continue
                
                category = self._classify_path(relative_path)
                if category:
                    self.files_by_category[category].append(relative_path)
        
        self._write_output()
        self._print_summary(time.time() - start_time)

    def _write_output(self):
        self._log(f"[*] æ­£åœ¨èšåˆæ¶æ„è“å›¾æ–‡ä»¶...", indent=1)
        with open(self.output_file, 'w', encoding='utf-8', errors='ignore') as out_f:
            out_f.write(f"--- START OF FILE monorepo_snapshot_blueprint.txt ---\n\n")
            for category in self.config.CATEGORY_ORDER:
                if category not in self.files_by_category:
                    continue

                self._log(f"Processing category: {category}", indent=2)
                
                for relative_path in sorted(self.files_by_category[category]):
                    file_path = os.path.join(self.project_path, relative_path)
                    try:
                        with open(file_path, 'r', encoding='utf-8', errors='ignore') as in_f:
                            content = in_f.read()
                        
                        out_f.write(f"--- START OF FILE {relative_path} ---\n")
                        out_f.write(content)
                        out_f.write(f"\n--- END OF FILE {relative_path} ---\n\n")
                        self._log(f"[+] Captured: {relative_path}", indent=3)
                    except Exception as e:
                        self._log(f"[!] Failed to read {relative_path}: {e}", indent=3)
            
            out_f.write(f"--- END OF FILE monorepo_snapshot_blueprint.txt ---\n")


    def _print_summary(self, duration):
        total_captured = sum(len(files) for files in self.files_by_category.values())
        
        print("\n" + "="*80)
        self._log("âœ… [Blueprint Scraper] æ‰«æå®Œæˆ!")
        self._log(f"â±ï¸  è€—æ—¶: {duration:.2f} ç§’")
        self._log(f"ğŸ“ æ‰«ææ–‡ä»¶æ€»æ•°: {self.total_files_scanned}")
        self._log(f"ğŸ¯ æ•è·è“å›¾æ–‡ä»¶æ•°: {total_captured}")
        self._log(f"ğŸ’¾ è¾“å‡ºæ–‡ä»¶: {self.output_file}")
        print("-"*80)
        
        self._log("æ•è·æ–‡ä»¶åˆ†ç±»ç»Ÿè®¡:")
        for category in self.config.CATEGORY_ORDER:
            if category in self.files_by_category:
                count = len(self.files_by_category[category])
                self._log(f"  - {category}: {count} ä¸ªæ–‡ä»¶", indent=1)
        print("="*80)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="V7.0 - Blueprint Edition: å¯¹é¡¹ç›®è¿›è¡Œé«˜å±‚çº§æ¶æ„æ‰«æï¼Œåªæå–è“å›¾æ–‡ä»¶ã€‚"
    )
    parser.add_argument(
        "project_path", nargs='?', default='.', 
        help="è¦æ‰«æçš„é¡¹ç›®æ ¹ç›®å½•è·¯å¾„ (é»˜è®¤ä¸ºå½“å‰ç›®å½•)ã€‚"
    )
    parser.add_argument(
        "--output", default="monorepo_snapshot_blueprint.txt", 
        help="è¾“å‡ºæ–‡ä»¶çš„åç§°ã€‚"
    )
    
    args = parser.parse_args()
    
    scraper = ProjectScraper(args.project_path, args.output, ScraperConfig)
    scraper.scrape()